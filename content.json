{"meta":{"title":"知识涓流","subtitle":null,"description":null,"author":"泡菜","url":"http://www.xmidou.com","root":"/"},"pages":[{"title":"categories","date":"2019-05-05T06:53:50.000Z","updated":"2019-05-05T06:54:50.586Z","comments":false,"path":"categories/index.html","permalink":"http://www.xmidou.com/categories/index.html","excerpt":"","text":""},{"title":"分类标签","date":"2019-05-23T06:52:25.000Z","updated":"2019-05-23T07:37:13.135Z","comments":false,"path":"tags/index.html","permalink":"http://www.xmidou.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"分布式事务处理方式总结","slug":"distributedTransaction","date":"2019-08-14T09:30:59.000Z","updated":"2019-08-14T09:38:50.820Z","comments":true,"path":"2019/08/14/distributedTransaction/","link":"","permalink":"http://www.xmidou.com/2019/08/14/distributedTransaction/","excerpt":"","text":"在项目开发中，经常会需要处理分布式事务。例如数据库分库分表之后，原来在一个单库上的操作可能会跨越多个数据库。系统服务化拆分之后，原来的在一个系统上的操作可能会跨越多个系统。就连我们平时经常使用到的缓存(如redis、memcache等)也可能涉及分布式事务，因为缓存和数据库是两个不同的实体，如何保证数据在缓存和数据库间的一致性也是要重点考虑的。分布式事务就是指事务要处理的资源分别位于分布式系统中的不同节点之上的事务。 对于单机系统，通常我们借助数据库实现本地事务，例如下面JDBC代码实现了一个事务： 1234Connection con = datasource.getConnection(); con.setAutoCommit(false); ... 执行CRUD操作，可能会涉及到多个表 ... con.commit()/con.rollback() 由于在分布式系统中，多个系统无法共用同一个数据库链接，所以无法简单借用上面的处理方式实现分布式事务。 下面将介绍几种本人在实际开发中使用过的处理分布式事务的方式，最后再引出分布式事务的相关理论并进行总结。 避免出现分布式事务 由于分布式事务比较难于处理，所以应该尽量避免分布式事务的发生。例如对于一个客户信息系统，由于注册用户数太多导致存储的数据量过大，所以对其进行分库分表存储。而客户信息模型又分为多个子模型，对应数据库中的多个表，例如客户基本信息表、客户登录账号表、客户登录密码表、客户联系方式表等等。假设登录账号表和客户基本信息表的关联关系如下所示： user_id和login_id分别是两个表的主键，user_id还作为login_info表的外键使两个表关联。在用户注册时会自动生成user_id和login_id的值。 user_info和login_info两个表分别采用user_id和login_id计算分库分表规则 。假设我们对每个模型分十库一百表存储，即存在user_info_00 ~ user_info_99一百个表，其中user_info_00 ~ user_info_09属于第一个库，user_info_10 ~ user_info_19属于第二个库，依次类推。 在分库分表之后，如果我们不仔细的考虑user_id和login_id的生成规则(例如随意生成一个数字字符串或简单使用递增sequence)，就可能导致同一个用户的user_info信息和login_info信息被存储到两个不同的库，这就会导致分布式事务发生。 面对这种问题，最好的解决思路就是考虑如何避免分布式事务的发生。只要想办法让跟一个用户相关的所有模型数据全部存入到一个库中，就可以避免分布式事务了。由于每个模型数据的分库分表路由规则又是由各个表的主键id决定的(例如user_id、login_id)，所以只要对各个表的主键生成规则进行定制，就可以保证一个用户的所有模型数据全部存到同一个库。假设有下面的id生成规则： 开始的两位是标识模型位，例如user_id以01开头，login_id以02开头。 接下来的11位是sequence递增序列号，如果想要更多的ID可以扩大这部分的位数，但对于存储用户信息而言，11位的长度足够。 接下来是分库分表位，如果每个模型的分库分表算法都相同，那么只要保证每个模型的主键ID的分库分表位都相同，就能保证一个用户的所有模型数据都会存到同一个库中。 最后一位是id校验位，这一位根据前面15位的内容生成，方便对一个id进行校验。 根据这个思想，我们可以在用户注册的时候先生成user_id，user_id的分库分表位可以随机生成。然后在为其它模型生成主键id时(例如login_id)，必须让这个模型的主键id的分库分表位与user_id的分库分表位相同。另外一点也要注意，一个表的查询条件不一定只有主键id一个，如果有其它查询条件列，那就要保证那一列的生成规则也要包含相同的分库分表位，否则就不能使用该列进行查询。 通过这种方式，就可以保证一个用户的所有模型数据全部存储到同一个库中，有效的避免分布式事务的发生。 事务补偿 通常情况下，应对高并发的一个主要手段就是增加分布式缓存(如redis)以提高查询性能。增加分布式缓存后系统查询数据的流程如下图： 即先尝试从缓存中查询数据，如果缓存命中就直接返回结果，否则尝试从DB中查询数据。如果查询DB命中则将数据补充到缓存，以备下次查询时可以命中缓存。 而在更新数据时，通常是先更新DB中的数据，DB写入成功后再更新缓存中的数据。那么就有一个问题， 如何保证缓存和DB间数据的一致性？ 由于缓存和DB是两个不同的实体，写入DB成功后再去更新缓存，如果缓存更新失败(例如网络抖动造成短暂的缓存不可用)就会造成缓存和DB的不一致。此时按照上图的查询逻辑，先查缓存就会查询到“脏”的数据，就会严重影响业务。这也是一个典型的分布式事务问题——缓存和DB要嘛同时更新成功，要嘛同时更新失败。解决这个问题的一个较好方式就是事务补偿。 我们可以在DB中创建一张事务补偿表transaction_log，transaction_log表可以和业务数据在一个库中，也可以在不同的库。在更新数据前，先将要更新的模型数据记录到transaction_log中。例如我们更新user_info表中的数据，就将userId记录到transaction_log中。 transaction_log记录成功后，再去更新业务数据表user_info中的内容，最后更新缓存中的userInfo数据。缓存更新成功后，就可以删除transaction_log表中对应的记录。 假设在更新完user_info表之后，由于网络抖动等原因导致缓存更新失败，则transaction_log表中对应的记录就会一直存在，表示这个事务没有完成的一种记录。 应用会创建一个定时任务，周期性的扫描transaction_log表中的记录(例如每隔2S扫描一次)。发现有符合条件的记录，就尝试执行补偿逻辑。例如更新用户信息时，DB中的user_info表更新成功，但缓存更新失败，定时任务发现transaction_log表中对应的记录没有删除且已经超过正常等待时间，就尝试使缓存和DB一致(可以删除缓存中对应的数据，也可以根据userId重新查询DB再补充的缓存)。补偿任务执行完成后，就可以删除transaction_log表中对应的记录。如果补偿任务执行再次失败，就保留transaction_log表中的记录，等待下个周期再次执行。 事务补偿这种方式保证的是事务的最终一致性，即如果发生意外，会存在一个时间窗口(例如2S)，在这个窗口内DB和缓存间是不一致的，但能保证最终两者的数据是一致的。至于定时任务周期的设定，要结合业务对“脏”数据的敏感程度以及系统的负载。 事务型消息 对于一个金融系统，假设有一个需求是用户注册成功后自动为用户创建一个账户。客户的信息维护在客户中心系统，客户的账户信息维护的账务中心系统，如果用户注册成功，必须保证客户的账户在账务系统创建成功。这显然也是一个分布式事务问题。 处理这个问题，显然也可以采用上一小节介绍的事务补偿机制来处理。但注册和开户并不要求一定是同步完成，且需要感知用户注册成功事件的系统并不只有账务系统一个(例如营销系统可能也需要感知用户注册成功的事件，给用户发优惠券)，所以使用消息机制异步通知更加合适。那么问题就变成了“如果用户注册成功，一定要保证消息发送成功”。 应对这种场景，可以使用事务型消息。但前提条件是使用的MQ中间件必须支持事务型消息，比如阿里的RocketMQ。目前市面上其它一些主流的MQ中间件都不支持事务型消息，比如Kafka和RabbitMQ都不支持。 下面的序列图是事务型消息的执行流程： 相比于普通消息，发布者发送消息后，MQ并不是马上将消息发送给订阅者，而仅仅是将消息持久化存储下来。 发送消息成功之后，发布者执行本地事务。例如我们例子中提到的用户注册。 根据本地事务执行是否成功，发布者决定对之前已经发送的消息是commit还是rollback。如果是rollback，MQ会删除之前存储的消息。假设我们这里发送commit。 MQ接收到发布者发送的commit后，才会将消息发送给订阅者。之后，就可以利用MQ的消息可靠传输特性促使订阅者完成剩余事务操作，例如上面例子中提到的开户操作。 细心的小伙伴会发现，如果在上图中的第5步发生问题导致发送commit失败，不还是会导致消息发布者和消息订阅者间事务的不一致吗？为了防止这种情况的发生，增加MQ超时回调机制。 下面的序列图是事务型消息commit失败时的执行流程： 当MQ长时间收不到发布者的commit/rollback通知时，MQ会回调发布者应用询问本地事务是否执行成功，是commit还是rollback之前的消息。发布者需要提供对应的callback，在callback中判断本地事务是否执行成功。 TCC两阶段提交 在某些场景下，一个分布式事务可能会涉及到多个参与者，且每个参与者需要根据自己当时的状态对事务进行响应。 假设这样一个场景，一个电商网站可以允许用户在支付时选择多种支付方式。例如总共需要支付100元钱，用户可以选择积分支付10元，账户余额支付90元。用户的积分由营销系统负责，账户余额由账务系统负责，订单的状态管理由订单系统负责。 首先，要先确保事务的各个参与者满足条件才能执行事务。例如积分系统要确保用户的积分超过10元钱，账务系统要确保用户的账户余额大于90元钱才能发起这次交易。 其次，就是要满足事务的原子性。这里的用户积分、用户余额、订单状态，要嘛全部处理成功，要嘛全部保持不变。 应对这种分布式事务场景，可以采用TCC两阶段提交的方式进行处理。 TCC将整个事务分成两个阶段——try和commit/cancel。TCC整个流程具有三种角色——事务发起者、事务参与者、事务协调者。以上面的订单支付为例，采用TCC实现处理事务的流程如下： 第一阶段try，订单系统分别调用promotion和account两个系统，询问该用户是否有足够的积分和账户余额。为了防止资源争抢，在这个阶段会对资源进行锁定，即营销系统会锁住用户的10元积分，账务系统会锁住用户的90元账户余额。 如果在try阶段有任何一个参与者处理失败(例如用户积分不够10元或者用户的余额不够90元)，则事务发起方(订单系统)会通知事务协调组件，后者会通知所有的事务参与者cancel在try阶段锁定的资源。 如果在try阶段所有的参与者都处理成功，则事务发起方通知协调者commit这个事务，协调者会通知所有的参与者完成事务的commit。这时系统会完成真正的余额和积分扣减。2.2步是假设订单系统也要更新订单的状态。 但仅是这样处理还是有一致性问题，例如在第二阶段commit时如果发生宕机、网络抖动等异常情况，就可能导致事务处于“非最终一致”状态(参与者只执行了try阶段，没有执行第二阶段。或部分参与者第二阶段commit成功，部分参与者commit失败)。为了应对这种情况，需要增加事务日志，以便发生异常时回复事务。 可以利用DB这种可靠存储来记录事务日志。日志中应包含事务执行过程中的上下文、事务执行状态、事务的参与者等信息。事务日志可以由事务发起发负责记录，也可以交由事务协调方进行记录。 事务日志可以由主事务记录日志和从事务记录日志组成： 主事务记录日志 用于记录事务发起方信息以及事务执行的整体状态。 从事务记录日志 用于记录所有的事务参与者信息，以及每个参与者所属的从事务的执行状态。与主事务记录日志是一对多的关系。 有了事务日志后，就可以周期性的不断扫描事务日志，找到异常中断的事务。根据事务日志中记录的信息，推动剩余的参与者commit或者cancel，以便使整个分布式事务达到“最终一致性”。 下面是commit阶段发生异常时的事务补偿逻辑： TCC两阶段提交的实现需要注意如下事项： 事务中的任何一个参与者都要确保在try阶段操作成功，在第二阶段就一定能commit成功。 参与者在实现commit和cancel接口时要考虑幂等，对重复的commit/cancel请求要能够正确处理。 业务上要考虑对两阶段中间状态(一阶段已完成，二阶段未开始)的处理。一般可以通过一些特殊文案，比如显示当前被冻结的账户余额。 对于状态型数据，当多个事务共同操作同一个资源时，要确保资源隔离。例如账户余额，确保不同的事务操作的金额是隔离的，彼此互不影响。 由于网络丢包、乱序等因素的影响，可能会导致参与者接收到一阶段try请求后，永远收不到commit/cancel请求，导致参与者的资源一直被锁定，永远不会被释放，这种情况叫做事务悬挂。为了防止事务悬挂的发生，可以在第一阶段try成功后，指定一个最大等待时间。超过这个最大等待时间就自动释放被锁定的资源。 总结 传统的单机事务应满足A(原子性)、C(一致性)、I(隔离型)、D(持久性)四个特性，属于刚性事务。由于分布式系统具有多个节点的特点，要求完全满足ACID这四个规范会非常的困难。所以就诞生了柔性事务BASE理论(Basic availability、Soft state、Eventual consistency)。 相比于单机事务，分布式事务在A和D上仍能够严格保证，但在C和I上就要有一定程度的限制放宽(允许看到中间状态数据、最终一致性)。","categories":[],"tags":[{"name":"设计","slug":"设计","permalink":"http://www.xmidou.com/tags/设计/"},{"name":"开发","slug":"开发","permalink":"http://www.xmidou.com/tags/开发/"}]},{"title":"非结构化数据存储在容器中的持久化","slug":"cloudStorgeDataPersistenceForContainer","date":"2019-08-14T08:06:14.000Z","updated":"2019-08-14T08:08:30.303Z","comments":true,"path":"2019/08/14/cloudStorgeDataPersistenceForContainer/","link":"","permalink":"http://www.xmidou.com/2019/08/14/cloudStorgeDataPersistenceForContainer/","excerpt":"","text":"在容器化应用程序设计中，每个容器间彼此隔离，独立扩展，并可作为处理某项大型网络应用的组件。有别于以往处理整个应用程序，大型的容器化应用程序可由数百个（甚至上千个）相关容器组合而成。这些应用程序支持敏捷设计、开发和部署方式。它们可以在生产环境中轻松扩展，非常适合于分布式、甚至基于云的混合式基础架构。 IT领域，变革的速度令人瞠舌。快速增长的数据，云计算规模的处理，以及的物联网设备正在推动我们向着更高效、可靠和可扩展的方向发展。传统的应用架构已日趋极限，我们正试图努力开发部署的新方案。所幸的是，最被看好的容器化技术——这项据称能够解决许多问题的技术（如果不能算是全部的话）——正成为应对上述难题的妙药良方。 在容器化应用程序设计中，每个容器间彼此隔离，独立扩展，并可作为处理某项大型网络应用的组件。有别于以往处理整个应用程序，大型的容器化应用程序可由数百个（甚至上千个）相关容器组合而成。这些应用程序支持敏捷设计、开发和部署方式。它们可以在生产环境中轻松扩展，非常适合于分布式、甚至基于云的混合式基础架构。 遗憾的是，容器在最初设计中并非用于实现全堆栈应用程序，亦不适合需要长期储存数据的应用。容器的设计初衷是可以轻易地大规模创建、部署微服务的应用层，并将微服务视为一种高度敏捷的中间件，在概念上无需持久的存储数据。 持之以恒 由于容器方式具有很强的灵活性、易于扩展、高效性，并面向云计算，在许多情况下这都是一种经济的部署模式，因此现在人们希望将其应用范围扩展到微服务之外。容器架构提供了更好的方式来构建现代化的应用程序，我们看到许多商业软件和系统供应商在内部开发中转向容器形式，甚至将其广泛部署，而且通常在上层保持对最终用户和IT管理人员的透明。大多数名列财富100强的企业已经开始以容器形式进行生产环境的第三方IT应用托管，尤其在内部应用、融合架构和专用的基础架构领域。 你或许会看到大型的、容器化的数据库，甚至存储系统的出现。然而，设计企业级的、长期存储数据的应用程序仍是不小的挑战，容器可能在分布式和混合基础架构中来回迁移。而数据需要控制、保护、受到管制和监督，所以很多时候持续数据存储需要更像是锚点那样，容器在这方面着实面临着短板。 容器架构使用到三种类型的存储：是镜像存储。这可以利用现有的共享存储进行交付，要求类似于服务器虚拟化环境中虚拟机镜像分发保护的平台架构。容器镜像的一项好处在于其存储容量相较于完整的虚拟机镜像小了许多，因为它们不会复制操作系统代码。此外，容器镜像的运行在设计之初便是固定的，因此可以更高效地存储、共享。但也因此，容器镜像无法存储动态应用程序的数据。 第二类需要存储的数据是容器的管理。当然，你同样可以借助现有存储完成这项工作。不论使用Docker、Kubernetes、Tectonic、Rancher还是其它类型的容器管理，都需要存储配置数据、日志记录等管理数据。 还有第三类存储，容器应用的存储，是挑战的。只有支持真正的微服务式编程时，容器代码可以直接写入镜像目录和文件。但是容器使用一种分层文件系统，将所有新写入的数据存储在临时虚拟层，层的容器镜像却未被修改。一旦容器消失——相比虚拟机，容器的设计寿命更短——所有的临时存储都会随之消散。 假如一个容器应用程序需要保存数据，一种方式是显示地在容器的全局命名空间内加载一个特定的系统数据卷——或在Kubernetes框架下的持久卷这样可以让容器直接方案读/写主机目录或文件系统。假如容器被关闭或重新启动，它依旧可以访问之前写入的，用于长期存放的数据。但这并不是一个简单易行的方式，需要考虑在容器之间共享数据，因此应用程序开发人员必须兼顾共享、锁定、争用和重启的问题。而且存储管理员如何甄别保护——快照、备份和灾难恢复产生的——成千上万由程序控制的海量数据。 此外，假如容器集群中的某一个容器位于另一台主机，那么存储管理员需要确保共享或分布式文件系统（例如NFS）在所有的集群主机上均保持同样的配置，甚至应用程序员可能要添加更多与I/O相关的代码，从而确保可靠的集群级别的共享。所幸的是，专家级的存储管理员会选择将现有的企业级存储（如NAS和SAN）带入这个全新的容器领域。如果他们与开发人员紧密合作，可以实际配置出高端的企业级生产环境。 不过，容器领域内的实践是让Agile DevOps具备相同的沙箱、测试与生产环境。从容器角度看，这种方式为最终用户提供动态配置，从而确保容器的移动和迁移。系统的存储配置越是静态和脆弱，容器化的好处便越是难以体现。 Docker等容器管理产品提供可插拔的卷管理。例如Flocker是开源Docker可插拔卷中的的替代品，可以通过集群智能管理、迁移数据卷及其容器。虽然Flocker的主要赞助商ClusterHQ已不复存在，但我们预计这种功能将持续发展，并在基准容器平台内变得日益本土化；Rancher Labs的“Convoy”项目正朝着这个方向发展。大多数（如果不说全部的话）传统存储供应商和云存储服务提供商为其存储阵列生成各类容器系统卷插件，这不失为在存储上持续投资的好方法。 存储即软件 相较于尝试将旧版存储强制迁移到新的容器环境中，不断增长的替代方案会引发新一波的软件定义存储（SDS）风潮来完成这项工作。SDS由一个存储操作系统和完全部署为软件层的服务构成，该服务层通常作为虚拟机呈现，不过现在其越来越多地部署为容器模式。容器化软件存储的快速发展是很容易想见得到的，以便于容器化应用程序使用存储服务。 相比在传统的生产环境中，服务器虚拟化环境通常基于大型而昂贵的主机集群，容器的托管体系架构能够轻松使用由更开放的、广泛而廉价的通用服务器组建起的私有、公有或混合云基础架构。这有些类似于Hadoop和Spark等大数据项目使用通用基础架构的优势，并且通过使用SDS和内存来讲我们从专用而昂贵的平台中释放出来。 SDS的另一项核心优势特别针对Ceph，Torus和GlusterFS等分布式容器方案，将存储以最适合的方式交付给容器集群。管理诸如GlusterFS之类的技术对传统的SAN管理员而言可谓是一项挑战，但容器化存储与身居来具有各种诸如敏捷性、可扩展性和可用性方面的优势，同时通过本地化数据存储改善应用程序性能。 简而言之，预融合和超融合容器设备使得内置本地容器存储功能（如Datera和Diamanti）变得更加简单。通过使用SDS来得到在同一平台设备格式下融合万物所需的灵活性和便捷性。虽然我们尚未有听到有企业真正在生产环境中使用融合容器托管方式，但未来的IT基础架构必将延续融合道路，同时建立更多云端服务。 当然，IT人员的工作在于判断是否为某家供应商专有的技术买单，或是转向免费的开源代码，加以投资，并封闭在该领域。假如要得到经过预先集成、验证的企业级功能和全天候的技术支持，通常需要长期选定某家供应商的开源分发或预融合的堆栈。换句话说，这不仅是选择传统的哪家供应商，更是选择供应商专有还是开源的技术，或是完全依赖自己的开发。 云端扩展的对象存储 容器化应用程序往往采取云计算架构，其体系架构要根据外部工作负载情况的变化、增长而持续扩展内部的服务。这种基于云的理念同样渗透到现代应用程序开发人员调用存储的方式。许多新的容器化应用程序是针对对象存储的I / O，而非传统的文件系统或数据块编写的。 大多数当前的容器环境在现实部署中平稳进行——当然在公有云中可谓例外，来自Hedvig、Qumulo和Scality等在线扩展对象存储恰好满足容器所需。在实施或迁移容器应用程序时，Amazon Web Services Simple Storage Service (S3)和类似的公有云已经开始将对象存储用作持久的存储层。 面向未来 我们尚未看到容器最终在数据存储方面会有怎样的表现。根据过去存储领域的发展演进经验来看，我们可能会看到“容器认知”存储的出现，其为容器配置而生，并配以适合的管理功能。就像虚拟机认知存储一样，我们应该还可以看到一项容器存储服务，可以保持数据并持续追溯——甚至在跨集群容器和跨云容器环境中。最终，我们期待看到使用服务器闪存和新兴的持续性闪存（如非易失性存储器快照）的容器认知缓存，并且和持续存储层相结合。 希望未来的容器认知存储可以兼顾到所有关键的方面，从容器清单到应用蓝图。我们同样希望在未来完成多容器环境的存储管理，可以追溯、预测和优化存储订阅，以满足持续容器运作所需。另外，存储认知的存储需要能通过简单的策略机制，随时随地地保护到所有数据、确保高可用性和灾难恢复。 以虚拟机形式呈现的服务器虚拟化花费了超过10年才替代掉企业数据中心中应用程序专用的物理服务器。现在，容器化应用程序似乎将会在一两年内替换许多完整的虚拟机应用。挑战在于我们能否为容器快速提供企业级持续性数据存储。","categories":[],"tags":[{"name":"设计","slug":"设计","permalink":"http://www.xmidou.com/tags/设计/"},{"name":"存储","slug":"存储","permalink":"http://www.xmidou.com/tags/存储/"}]},{"title":"谈谈云存储性能优化","slug":"cloudStorgePerformance","date":"2019-08-14T07:24:08.000Z","updated":"2019-08-14T08:09:39.754Z","comments":true,"path":"2019/08/14/cloudStorgePerformance/","link":"","permalink":"http://www.xmidou.com/2019/08/14/cloudStorgePerformance/","excerpt":"","text":"公共云供应商所提供的存储服务选择有限，这就使得其优化成为一项挑战。使用下文中的这些小贴士可有助于提升性能并确保您的工作负载顺利运行。 随着企业在公共云中部署了越来越多的存储资源，每一家供应商所提供服务的运行性能可能对相关的工作负载产生意义深远的影响。诸如存储服务等级、网络连接性以及应用设计等问题都会影响应用程序的实际运行性能。 工作负载的运行取决于存储服务，所以在工作负载的运行过程中实现和保持一定的存储性能等级是非常重要的。 使用如下这五种策略可实现公共云存储服务的性能优化。 精心选择存储类型 传统企业完全控制IT资源及其运行性能，但公共云的运行方式则是截然不同的。云存储服务供应商是不会为了用户业务能够创造出的功能而改变其产品的，这样会破坏使公共云功能多样化的速度与规模。 用户不得不在有限的存储服务菜单中进行选择，而每一个服务选项都有其各自的优缺点。公共云存储服务性能优化的方法之一就是了解这些限制，并根据性能要求进行仔细选择。 例如，亚马逊网络服务(AWS)用户通常会为低延迟、高流量的频繁访问数据选择亚马逊简单存储(S3)标准，尽管其运行性能是可变的。其挑战就是以尽可能低成本选择一种存储服务，同时所提供的性能和恢复能力都是最适合用户工作负载的。如果用户已经选择了一项服务，但在实际使用中发现其不足，那么可考虑将数据迁移至另一个服务层，一个不同的存储服务或者甚至另行选择一家公共云供应商。 监控和测量有意义的指标 用户需要知道公共云存储服务何时是正常运行的，何时运行不稳定以及何时服务发生中断。监控和测量相关指标可有助于用户确定系统的可用性和了解实际的运行性能。可考虑选择云供应商所提供的本地监控服务，例如亚马逊CloudWatch、Azure Monitor和谷歌云平台(GCP)Stackdriver Monitoring。 这种监控与测量服务可简化故障诊断，并有助于工作负载架构与设计的设施改进。例如，监控报告可帮助企业用户识别网络或存储性能中存在的瓶颈。监控工具的强大之处还在于它能够推动服务配置变更，例如使用更多的存储容量或集成其他存储服务。 工作负载审查及其重新设计 许多其他企业将使用与您使用相同的存储服务，这就会导致出现意想不到的性能变化。用户无法自行更改供应商的公共云存储服务来解决这个问题，但是他们可以通过更改他们工作负载的架构和设计来实现性能优化。 例如，如果用户在一个公共云区域中移动或部署工作负载，而工作负载的存储资源则位于另一个不同的区域，那么其性能可能会有所下降。为了解决这个问题，架构师可以将原始存储库复制到位于新区域中的副本存储资源，并将工作负载重新指向复制的存储资源。架构师也可以使用缓存方法。例如，对于敏感的数据库工作负载，可以使用诸如亚马逊ElastiCache或Azure Redis Cache的服务来提供高性能、内存内的云缓存功能。 开发人员应当评估应用程序的存储敏感度并考虑设计变更。例如，异步通信可能比同步通信更容易产生延迟和中断，而异步操作则会带来更大的数据丢失风险。最终，一个依赖于公共云存储服务的工作负载必须适应该存储的行为。 评估混合云存储机会 当本地工作负载无法克服公共云存储服务的性能限制时，使用特制工具可加速数据中心与云端的连接性。 这种混合云实施的一个示例就是AWS Storage Gateway，企业通常将其作为一个设施部署在他们自己的数据中心内。网关的工作模式主要有三种：文件、卷标和磁带。作为一个文件网关，本地工作负载会发送文件对象至亚马逊S3。企业主要使用这种模式进行备份和灾难恢复工作。作为卷标网关，本地工作负载会访问云中的iSCSI卷标。企业用户会使用卷标模式进行快照和其他备份。此外，卷标模式还支持本地缓存功能，所以频繁访问的数据也可以保存在本地存储器中，而其他数据保存在云端。在磁带网关模式下，用户可以将现有基于磁带的备份系统作为一个虚拟磁带库扩展至云。 增强连接性 性能问题不一定源于云存储服务供应商或服务本身，但是这个问题可以通过互联网连接的限制予以解决。公共网络常常伴随着意外拥塞和中断的风险，这两种风险都会造成存储流量中断并降低性能。 一个选择就是增加WAN到公共互联网的带宽。为了实现这一点，可用高带宽的WAN链接(例如万兆以太网，GbE)或更高速的网络链接替代现有的WAN链接。作为替代方案，可使用多个低带宽WAN链接的组合(例如两个或多个千兆链接)。多个链路还可提升网络的可用性——如果有一个链路发生故障，那么另一个链路可以保持连接。 企业还可以在他们的数据中心和公共云存储服务之间使用专用网络连接服务。这些服务的示例包括AWS Direct Connect、Azure ExpressRoute 和谷歌Cloud Interconnect。一个专用的高性能连接可以降低公共互联网的可变性，同时改善有限WAN带宽的使用。","categories":[],"tags":[{"name":"设计","slug":"设计","permalink":"http://www.xmidou.com/tags/设计/"},{"name":"存储","slug":"存储","permalink":"http://www.xmidou.com/tags/存储/"}]},{"title":"谈谈云存储架构","slug":"cloudStorgeFamework","date":"2019-08-14T07:17:49.000Z","updated":"2019-08-14T07:20:24.582Z","comments":true,"path":"2019/08/14/cloudStorgeFamework/","link":"","permalink":"http://www.xmidou.com/2019/08/14/cloudStorgeFamework/","excerpt":"","text":"在企业内部服务平台中，首先需要实现云存储功能，以提供各部门用户数据的存储功能，方便用户获取各自需要的数据，包括GPS、视频、语音等模拟和数字信息等数据。 在企业内部服务平台中，首先需要实现云存储功能，以提供各部门用户数据的存储功能，方便用户获取各自需要的数据，包括GPS、视频、语音等模拟和数字信息等数据。其次需要接入消息与通讯系统，如350兆集群呼叫，手机、移动终端、 固话，及Mail，MSN、QQ、微信等即时通讯(IM Instant Messenger)，以实现动态消息推送和位置服务。第三是实现业务功能开发与运行，如在线播放云存储中的视频监控图像、照片及相关资料，以及各业务子系统的运行，为一线用户和领导提供分析和指挥决策依据。为此需要相应的基础软硬件资源，如服务器、存储和网络设备、操作系统和数据库等商用软件。企业云架构示意见图1。云存储、通讯及消息、业务运行系统和软硬件基础资源这四个基本要素构成了一个面向终端用户的操作系统平台，或称为企业云，其能够通过各种浏览器或手机App及PC机随时访问，满足用户在任意时刻、任意地点查看信息的需求。 作为企业云的核心是存储和计算，其它都构建在存储和计算之上的基础服务和用户运用。企业云主要涉及数据存储架构和用户访问优化等两方面的技术，下面分别予以简述。 云存储架构设计 云存储主要是为了存储数据，方便用户访问，同时也是为了解决信息共享问题。在云存储建立之前，各业务部门均是自建专用系统，网络虽然相通，但由于数据分散存储在各自系统中，导致信息在业务协同时关联、互查和引用不流畅。以前各系统间的数据整合和共享主要靠交换接口标准化等SOA方式来实现[4]，对于非结构化数据几乎无法实现，且改造各子系统的工作量巨大和繁琐。 采用云存储技术就可以克服上述问题，本文采用HDFS(Hadoop Distributed File System)分布式文件系统的存储方式，原各业务信息管理系统的数据通过Sqoop工具导入，HDFS实现数据层面的共享。HDFS包括主控服务器(同时配置备用主控服务器以便在故障时接管服务)，多个数据服务器(存储节点)，前端接入终端服务消息平台及各业务子系统数据库服务器。 图2 分布式文件系统示意图 主控服务器Master负责维护整个文件系统的命名空间与路由，以提供用户使用。该分布式系统架构***的缺点是主控服务器为单点结构，一旦出现故障将造成全系统瘫痪，故在实际应用中采用HA、UCARP等容灾备份，以便在故障时接管服务。主控服务器的命名空间结构采用目录树结构，建立元数据到数据服务器的映射关系，文件之间的关系等。为了提高检索效率，可以采取元数据内存化管理方式。主控服务器通过心跳线方式轮询数据服务器(DS)，当发现有DS宕机时，对一些副本数不足的文件(块)执行复制计划，也可根据DS数量增减需要执行副本迁移任务。 数据服务器主要解决海量数据的低成本存储和快速检索，提高数据存储的安全性问题。其解决方案是将大块数据划分为小数据块，然后均匀分布到多台数据服务器上，每个数据服务器存储的文件数量就少了，对于大文件数据的处理方法是将大文件划分成多个相对较小的片段存储在多个数据服务器上，把单个数据服务器上存储的文件数降到单机能解决的规模，以此降低存储设备成本和提高效率，并通过多副本复制来提高数据安全性。 终端服务平台 企业协同作业的终端服务平台又称为“永远在线推送平台”(AOI Always Online Infrastructure)，该平台是以协同作业应用为导向，以指挥中心的“推送”技术为基础，为一线人员提供统一的消息推送服务，实现了将消息和内容实时推送到终端的全新体验。 永远在线推送平台(AOI)包括终端中间件和在线服务器，终端中间件提供各类移动和固定终端的接入以及各终端间的通信路由功能;在线服务器提供统一的永远在线连接安全认证、消息缓存服务、在线业务处理子系统。终端服务消息平台示意图如下： 其中，SIP(Session Initiation Protocol)网主要实现会话功能，这些会话可以是Internet多媒体会议、IP电话或多媒体分发，会话的参与者可以通过组播(multicast)、网状单播(unicast)或两者的混合体进行通信。 XMPP(The Extensible Messaging and Presence Protocol)网主要用于服务类实时通讯，即时消息(IM)及在线现场探测[2]。XMPP的核心是XML流传输协议，借助于XML易于解析和阅读的特性，使得XMPP的协议能够允许网络用户简便和流畅地向其他用户发送信息。 终端服务消息平台采用软交换技术(SS Software Switching)吸取了IP、ATM、IN、TDM等技术的优点，采用开放的分层体系结构，不但实现了各种通讯协议的兼容，更重要的是实现了业务系统的融合，为终端用户提供了统一的消息和内容服务接口。","categories":[],"tags":[{"name":"设计","slug":"设计","permalink":"http://www.xmidou.com/tags/设计/"},{"name":"存储","slug":"存储","permalink":"http://www.xmidou.com/tags/存储/"}]},{"title":"URL长短变换","slug":"changLurlToSurl","date":"2019-07-15T03:02:51.000Z","updated":"2019-07-15T10:21:09.489Z","comments":true,"path":"2019/07/15/changLurlToSurl/","link":"","permalink":"http://www.xmidou.com/2019/07/15/changLurlToSurl/","excerpt":"","text":"将一个长URL变成短及原理分析短址本质上是实现了一个映射函数 f: X - Y 。而这个映射函数必须同时具有两个特点： 12如果 x1 != x2, 则 f (x1) != f(x2);同样，对于每一个 y, 也能够找到唯一的一个 x 使得 f(x) = y; 如何将长URL生成短URL 短地址从URL输入到页面展现到底发生了什么？ 短链接的设计思路 发号器的设计思路 如何将长URL生成短URL1http://longlonglong.url --&gt; http://short.url 短地址在实际场景中还有一些好处： 较短的网址可以放在微博的限制字数里，节约网址长度、更加方便社交化传播 规避网址中的关键词、屏蔽域名、隐藏真实地址 由于存在长短网址的映射的中间层，可以更加方便URL的管理，如暴力广告等信息的屏蔽、跟踪点击量、地域分布等数据统计及挖掘工作 1https://news.sina.com.cn/gov/xlxw/2019-07-15/doc-ihytcerm3703831.shtml 一个比较简单的做法就是使用百度的短地址服务 http://dwz.cn/ ，这样就可以生成如下所示的短地址，无论访问长地址还是短地址其实都是一样的可以访问到最终的真实地址： 1https://dwz.cn/g0K4oEWD 123456有很多提供短地址服务的平台，例如：- 新浪：http://sina.lt/- 百度：http://dwz.cn/- 0x3：http://0x3.me/- MRW：http://mrw.so/- 谷歌：https://goo.gl/ 短地址从URL输入到页面展现到底发生了什么？ 当我们在浏览器里输入https://dwz.cn/g0K4oEWD时 DNS首先解析获得 http://dwz.cn 的 IP 地址 当 DNS 获得 IP 地址以后（比如：180.101.212.104），会向这个地址发送 HTTP GET 请求，查询短码 g0K4oEWD http://dwz.cn.cn 服务器会通过短码 g0K4oEWD 获取对应的长 URL 请求通过 HTTP 301 转到对应的长 URL https://news.sina.com.cn/gov/xlxw/2019-07-15/doc-ihytcerm3703831.shtml 1234301 是永久重定向，302 是临时重定向。短地址一经生成通常就不会变化，301 是符合 http 语义的，同时对服务器压力也会有一定减少。301 redirect:：301代表永久性转移(Permanently Moved)，301重定向是网页更改地址后对搜索引擎最友好的方法，只要不是暂时搬移的情况，都建议使用301来做转址。302 redirect:：302代表暂时性转移(Temporarily Moved )，在前些年，不少Black Hat SEO曾广泛应用这项技术作弊。各大主要搜索引擎均加强了打击力度，像Google对BMW德国网站的惩罚。即使网站客观上不是spam，也很容易被搜寻引擎误判为spam而遭到惩罚。服务器坚持重定向而不是立即响应用户想要查看的网页有一些有趣的原因。一个原因与搜索引擎排名有关。请参阅，如果同一页面有两个网址，比如http://www.igoro.com/和http://igoro.com/ ，搜索引擎可能会将它们视为两个不同的网站，每个网站都有较少的传入链接和因此排名较低。搜索引擎理解永久重定向（301），并将来自两个源的传入链接组合成单个排名。此外，相同内容的多个URL不支持缓存。当一段内容具有多个名称时，它可能会在缓存中多次出现。**URL完整格式为：协议://用户名:密码@子域名.域名.顶级域名:端口号/目录/文件名.文件后缀?参数=值#标志** 从输入URL到页面加载完成的过程比较粗的可以说经历了如下阶段： 在浏览器中输入URL并确认 URL解析/DNS解析查找域名IP地址 网络连接发起HTTP请求 HTTP报文传输过程 服务器接收数据 服务器响应请求/MVC 服务器返回数据 客户端接收数据 浏览器加载/渲染页面 打印绘制输出 关于DNS部分需要补充的知识如下，DNS的域名解析是递归的： 根域名服务器是用来查顶域权威服务器用的，作为全球因特网DNS体系的固定统一入口。全球13组根域名服务器中有 10 组在美国。 拓展阅读：DNS层面是可以进行DNS劫持的，DNS劫持又称域名劫持，是指在劫持的网络范围内拦截域名解析的请求，分析请求的域名，把审查范围以外的请求放行，否则返回假的IP地址或者什么都不做使请求失去响应，其效果就是对特定的网络不能访问或访问的是假网址。 DNS劫持(DNS钓鱼攻击)十分凶猛且不容易被用户感知，曾导致巴西最大银行巴西银行近1%客户受到攻击而导致账户被盗。黑客利用宽带路由器的缺陷对用户DNS进行篡改——用户只要浏览一下黑客所掌控的WEB页面，其宽带路由器的DNS就会被黑客篡改，因为该WEB页面设有特别的恶意代码，所以可以成功躲过安全软件检测，导致大量用户被DNS钓鱼诈骗。 短链接的思路短链接的实现有些人提出了压缩算法和Hash映射等等，有人也在知乎进行了讨论（下一节会提出），其实这些的方向都错了会钻到牛角尖里。 正确的思路，是做一个发号器，通过长短链接的一一映射关系进行统一的管理。每过来一个长地址，就让发号器发一个号即可，长地址和短地址的映射关系甚至可以放在mysql。 1https://dwz.cn/g0K4oEWD 为例，我们再简化一下，哪怕是最简单的id自增都是简单实用的，根据长地址依次生成https://dwz.cn/0 、 https://dwz.cn/1 ...... 短地址的生成是一个读多写少的情况，技术上可以思考更全面一些，比如： 生成短链接以前使用Bloom Filter判断是否存在冲突 对总链接数做好监控，防止地址太多超过上限 防攻击做好，防止耗尽链接池初始资源 一些统计的加强 发号器的实现最核心的方式之一是多进制的使用。 我们上篇文章介绍的UUID，以及之前介绍过的Snowflake雪花算法，还有百度开源的基于Snowflake的Uidgenerator、美团开源的leaf都是发号器。 目前业界使用Apache亮哥的sharding-jdbc，一般都会采取其内置的Snowflake算法，关于二次改造我这里列举一个58沈剑在《架构师之路》系列中提出的例子。 发号器的设计思路在设计发号器之初，必须要做的是评估发号器的容量。 这是一种设置 id 自增，一个 10进制 id 对应一个 62进制的数值，1对1，也就不会出现重复的情况。这个利用的就是低进制转化为高进制时，字符数会减少的特性。 1进制转换工具 http://tool.lu/hexconvert/ 以新浪微博微为例，如果新浪微博日活用户量是1亿，如果每个人每天发0.1条带URL的新浪微博，那么转换为短地址我们要考虑总量和读写的压力，微博场景下是读多写少的。 对于写来说，每天产生一千万微博数量，那么每年大概是0.1亿*365=36.5亿，如果采用based62上生成6位， 短址的长度一般设为 6 位，而每一位是由 [a - z, A - Z, 0 - 9] 总共 62 个字母组成的，所以 6 位的话，总共会有 62^6 ~= 568亿种组合，够用15年。在google URL shortener 服务中，短址长度为 5，大概有9亿多种组合。 如果按照秒来算的话，一天86400秒，每天写的平均QPS大概在 0.1亿 /86400秒=115QPS，我们可以把峰值设置为500QPS。所以500QPS就是发号器设置的QPS写峰值，也是这个系统设计之初需要达到的QPS。 对于读来说，读比写要多，比如一亿人一天只有十分之一的人发微博，但是每个人都会点击10条别人的微博。点击这个URL的峰值我们可以初步计算为 1亿*10/86400 = 11万5000 QPS。这么大的QPS最好使用分布式缓存Redis去存储。 对于存储来说，如果一个URL是100bytes（字节），那么每天产生一千万的微博总量是 100bytes 1千万 / 1024/1024/1024 = 0.93G，每年产生0.93G365=339G=0.3T。所以准备1T的硬盘，没有特殊情况，可以用3年。 在stackoverflow上也有老外提出了自增序列算法的解答（ https://stackoverflow.com/questions/742013/how-do-i-create-a-url-shortener ） 于每一个长地址，我们可以根据它的ID，得到一个6位的 62 进制数，这个6位的 62 进制数就是我们的短址: 123456789 public ArrayList&lt;Integer&gt; base62(int id) &#123; ArrayList&lt;Integer&gt; value = new ArrayList&lt;Integer&gt;(); while (id &gt; 0) &#123; int remainder = id % 62; value.add(remainder); id = id / 62; &#125; return value;&#125; 举个例子，对于 ID = 138，通过 base62(138), 我们得到 value = [14, 2]。根据上面的对应规则表，我们可以得到其对应的短址为：aaaabn 通过短址找到所对应的长地址，方法也很简单，就是把62进制数转成10进制数即可，这样我们就可以得到长地址的ID了。 How to resolve a shortened URL to the initial ID The reverse is even easier.You just do a reverse lookup in your alphabet. 1、e9a~62~ will be resolved to “4th,61st,and 0th letter in the alphabet”. 2、Now find your database-record with WHERE id = 19158 1234567891011121314 public static int base10(ArrayList&lt;Integer&gt; base62) &#123; //make sure the size of base62 is 6 for (int i = 1; i &lt;= 6 - base62.size(); i++) &#123; base62.add(0, 0); &#125; int id = 0; int size = base62.size(); for (int i = 0; i &lt; size; i++) &#123; int value = base62.get(i); id += (int) (value * Math.pow(62, size - i - 1)); &#125; return id;&#125; MD5进制算法算法一自增序列算法 也叫永不重复算法 设置 id 自增，一个 10进制 id 对应一个 62进制的数值，1对1，也就不会出现重复的情况。这个利用的就是低进制转化为高进制时，字符数会减少的特性。 如下图：十进制 10000，对应不同进制的字符表示。 短址的长度一般设为 6 位，而每一位是由 [a - z, A - Z, 0 - 9] 总共 62 个字母组成的，所以 6 位的话，总共会有 62^6 ~= 568亿种组合，基本上够用了。 算法二 将长网址 md5 生成 32 位签名串,分为 4 段, 每段 8 个字节 对这四段循环处理, 取 8 个字节, 将他看成 16 进制串与 0x3fffffff(30位1) 与操作, 即超过 30 位的忽略处理 这 30 位分成 6 段, 每 5 位的数字作为字母表的索引取得特定字符, 依次进行获得 6 位字符串 总的 md5 串可以获得 4 个 6 位串,取里面的任意一个就可作为这个长 url 的短 url 地址 这种算法,虽然会生成4个,但是仍然存在重复几率; 两种算法对比第一种算法的好处就是简单好理解，永不重复。但是短码的长度不固定，随着 id 变大从一位长度开始递增。如果非要让短码长度固定也可以就是让 id 从指定的数字开始递增就可以了。百度短网址用的这种算法。上文说的开源短网址项目 YOURLS 也是采用了这种算法。源码学习 第二种算法，存在碰撞（重复）的可能性，虽然几率很小。短码位数是比较固定的。不会从一位长度递增到多位的。据说微博使用的这种算法。 我使用的算法一。有一个不太好的地方就是出现的短码是有序的，可能会不安全。我的处理方式是构造 62进制的字母不要按顺序排列。因为想实现自定义短码的功能，我又对算法一进行了优化，下文会介绍。 流程图自增序列算法流程图 据说微博使用的这种算法： 将长网址 md5 生成 32 位签名串,分为 4 段, 每段 8 个字节 对这四段循环处理, 取 8 个字节, 将他看成 16 进制串与 0x3fffffff(30位1) 与操作, 即超过 30 位的忽略处理 这 30 位分成 6 段, 每 5 位的数字作为字母表的索引取得特定字符, 依次进行获得 6 位字符串 总的 md5 串可以获得 4 个 6 位串,取里面的任意一个就可作为这个长 url 的短 url 地址 这种算法存在碰撞（重复）的可能性，短码位数固定，生成之前需要进行防碰撞的检测 自增序列算法 + 用户自定义短码 流程图 实现自定义短码 数据库增加一个类型 type 字段，用来标记短码是用户自定义生成的，还是系统自动生成的。如果有用户自定义过短码，把它的类型标记自定义。每次根据 id 计算短码的时候，如果发现对应的短码被占用了，就从类型为自定义的记录里选取一条记录，用它的 id 去计算短码。这样既可以区分哪些长连接是用户自己定义还是系统自动生成的，还可以不浪费被自定义短码占用的 id; 保留了 1 到 2 位的 短码，从三位的短码开始生成的。就像域名的保留域名一样，好的要自己预留; 位数 个数 区间 1位 62 0 - 61 2位 3844 62 - 3843 3位 约 23万 3844 - 238327 4位 约 1400万 238328 - 14776335 5位 约 9.1亿 14776336 - 916132831 6位 约 568亿 916132832 - 56800235583 数据表设计 ​ links 表 字段 含义 id link_id url 长连接 keyword 短链接码 type 系统: “system” 自定义: “custom” insert_at 插入时间 updated_at 更新时间 后期功能扩展 统计：点击量、访问的 ip 地域、用户使用的设备 管理后台：删除、数据量 登录：权限管理 设置密码：输入密码才可以继续访问","categories":[],"tags":[{"name":"设计","slug":"设计","permalink":"http://www.xmidou.com/tags/设计/"},{"name":"开发","slug":"开发","permalink":"http://www.xmidou.com/tags/开发/"}]},{"title":"本地文件检索设计","slug":"design-searchfile","date":"2019-05-23T10:34:16.000Z","updated":"2019-05-24T01:57:15.571Z","comments":true,"path":"2019/05/23/design-searchfile/","link":"","permalink":"http://www.xmidou.com/2019/05/23/design-searchfile/","excerpt":"","text":"[TOC] (一)操作系统类型文件的检索功能需要包含: windows操作系统 liunx操作系统 (二)需求描述要求： 12345- 提供java的SDK包，以maven的方式引入到业务系统中使用。- 调用查询的接口- 指定路径下的所有子目录的检索（如：D:\\test或/root/test） 检索条件： 123- 文件名搜索- 文件内容搜索 检索范围： 1234567- 指定文件大小- 指定文件扩展名- 指定最后更新时间- 支持全文及文件件名的模糊搜索 实际应用的场景： 1每天文件的生成的数量为800个左右，单个文件大小为200K-300K，极少情况个别文件大小在100M-500M; 文件格式： 1doc、docx、xml、txt、pdf、jpg、png 特殊约定： 1234567- pdf、doc、docx等内嵌图片的内容无法支持内容的检索；- jpg、png等图片类文件无法支持内容检索；- 视频文件无法支持内容检索；- 音频文件无法支持内容检索； 依赖工具1、liunx依赖系统自有带的命令行进行文件检索(find、grep、locate) 2、windws操作系统利用第三方搜索工具：everything-SDK-windows (三)web微服务客户端SDK和服务器通过http方式交互； 客户端： 提供一个客户端的SDK，并定义搜索接口，指定传入参数： 1、检索路径（必填） 2、文件名（文件名和文件内容选填其一） 3、文件内容（文件名和文件内容选填其一） 4、指定文件大小（选填） 5、指定文件扩展名（选填） 6、指定最近多少时间内更新的文件（选填） 服务端： 创建spring boot web程序，包装http接口，服务器调用： windows操作系统： 1通过everything-sdk检索本地磁盘，返回文件路径和文件名列表 liunx操作系统： 1执行shell命令(find、grep、locate)检索本地磁盘，返回文件路径和文件名列表 服务拓朴图： 结语： 客户端+服务端的设计模式，主要为了解决跨服务器的远程磁盘检索的要求； 优势： 1一个客户端可以在多个服务器进行文件检索； 缺点： 1需要将服务端部署到要检索磁盘的服务器上；","categories":[],"tags":[{"name":"设计","slug":"设计","permalink":"http://www.xmidou.com/tags/设计/"},{"name":"开发","slug":"开发","permalink":"http://www.xmidou.com/tags/开发/"}]},{"title":"(一)hexo学习笔记","slug":"hexo-use","date":"2019-05-23T03:39:08.000Z","updated":"2019-05-23T09:40:42.185Z","comments":true,"path":"2019/05/23/hexo-use/","link":"","permalink":"http://www.xmidou.com/2019/05/23/hexo-use/","excerpt":"","text":"[TOC] hexo发布到github的坑当使用: 1hexo d 或者hexo deploy 发布到github,如果已经绑定了自己申请的域名，将会被重置失效， 因此，在发布完后，需要重新设置域名的映射关系。 hexo-use-1 hexo-use-2 点击 save 保存后，又可以正常访问网站了。","categories":[],"tags":[{"name":"技术","slug":"技术","permalink":"http://www.xmidou.com/tags/技术/"},{"name":"站长","slug":"站长","permalink":"http://www.xmidou.com/tags/站长/"}]},{"title":"第一个博客的创建","slug":"first-blog","date":"2019-05-06T03:39:08.000Z","updated":"2019-05-23T09:29:57.527Z","comments":true,"path":"2019/05/06/first-blog/","link":"","permalink":"http://www.xmidou.com/2019/05/06/first-blog/","excerpt":"","text":"[TOC] 我的第一个博客的创建一直想做一个自己的Blog，经过曲折的过程，现在终于成形了。在这里记录下创建第一个Blog的过程。 一、托管的Blog策略​ github pages可以为一个注册用户提供一个主域名的的绑定功能。而且在构建网站面可以使用hexo发布到github还是比较方便了。考虑再三，还是接受了这个方便，毕竟是第一次做网站的同学，也不用考虑太多，先做起来，有经验了后面就可以再变通。 1、组合方案：1、github pages做为网站托管 2、hexo进行网站编排和和管理发布 3、typora工具是目前比较好的markdown语言编排工具，可以用来写文章和排版，生成的MD文件放到hexo再发布到github网站。 二、hexo+github搭建免费的个人博客1、准备工具在开始一切之前，你必须已经： 有一个github账号，没有的话去注册一个； 安装了node.js、npm，并了解相关基础知识； 安装了git for windows（或者其它git客户端） 本文所使用的环境： Windows7-64X node.js_12.0.1 git_1.9.2 hexo_3.8.0 2、搭建github博客2.1 创建仓库​ 新建一个名为你的用户名.github.io的仓库，比如说，如果你的github用户名是test，那么你就新建test.github.io的仓库（必须是你的用户名，其它名称无效），将来你的网站访问地址就是 http://test.github.io 了，是不是很方便？ 由此可见，每一个github账户最多只能创建一个这样可以直接使用域名访问的仓库。 几个注意的地方: 1231. 注册的邮箱一定要验证，否则不会成功；2. 仓库名字必须是：`username.github.io`，其中`username`是你的用户名；3. 仓库创建成功不会立即生效，需要过一段时间，大概10-30分钟，或者更久，我的等了半个小时才生效； 创建成功后，默认会在你这个仓库里生成一些示例页面，以后你的网站所有代码都是放在这个仓库里啦。 2.2 绑定域名​ 当然，你不绑定域名肯定也是可以的，就用默认的 xxx.github.io 来访问，如果你想更个性一点，想拥有一个属于自己的域名，那也是OK的。 首先你要注册一个域名，域名注册以前总是推荐去godaddy，现在觉得其实国内的阿里云也挺不错的，价格也不贵，毕竟是大公司，放心！ 绑定域名分2种情况：带www和不带www的。 域名配置最常见有2种方式，CNAME和A记录，CNAME填写域名，A记录填写IP，由于不带www方式只能采用A记录，所以必须先ping一下你的用户名.github.io的IP，然后到你的域名DNS设置页，将A记录指向你ping出来的IP，将CNAME指向你的用户名.github.io，这样可以保证无论是否添加www都可以访问，如下： first-blog_1 然后到你的github项目根目录新建一个名为CNAME的文件（无后缀），里面填写你的域名，加不加www看你自己喜好，因为经测试： 如果你填写的是没有www的，比如 mygit.me，那么无论是访问 http://www.mygit.me 还是 http://mygit.me ，都会自动跳转到 http://mygit.me 如果你填写的是带www的，比如 www.mygit.me ，那么无论是访问 http://www.mygit.me 还是 http://mygit.me ，都会自动跳转到 http://www.mygit.me 如果你填写的是其它子域名，比如 abc.mygit.me，那么访问 http://abc.mygit.me 没问题，但是访问 http://mygit.me ，不会自动跳转到 http://abc.mygit.me 另外说一句，在你绑定了新域名之后，原来的你的用户名.github.io并没有失效，而是会自动跳转到你的新域名。 2.3 配置SSH KEY​ 为什么要配置这个呢？因为你提交代码肯定要拥有你的github权限才可以，但是直接使用用户名和密码太不安全了，所以我们使用ssh key来解决本地和服务器的连接问题。 1$ cd ~/. ssh #检查本机已存在的ssh密钥 如果提示：No such file or directory 说明你是第一次使用git 1ssh-keygen -t rsa -C &quot;邮件地址&quot; 然后连续3次回车，最终会生成一个文件在用户目录下，打开用户目录，找到.ssh\\id_rsa.pub文件，记事本打开并复制里面的内容，打开你的github主页，进入个人设置 -&gt; SSH and GPG keys -&gt; New SSH key： first-blog_2 将刚复制的内容粘贴到key那里，title随便填，保存。 2.4 测试是否成功1$ ssh -T git@github.com # 注意邮箱地址不用改 如果提示Are you sure you want to continue connecting (yes/no)?，输入yes，然后会看到： 1Hi liuxianan! You&apos;ve successfully authenticated, but GitHub does not provide shell access. 看到这个信息说明SSH已配置成功！ 此时你还需要配置： 12$ git config --global user.name &quot;liuxianan&quot;// 你的github用户名，非昵称$ git config --global user.email &quot;xxx@qq.com&quot;// 填写你的github注册邮箱 具体这个配置是干嘛的我没仔细深究。 3、使用hexo3.1 hexo简介​ Hexo是一个简单、快速、强大的基于 Github Pages 的博客发布工具，支持Markdown格式，有众多优秀插件和主题。 官网： http://hexo.iogithub: https://github.com/hexojs/hexo 3.2 hexo原理​ 由于github pages存放的都是静态文件，博客存放的不只是文章内容，还有文章列表、分类、标签、翻页等动态内容，假如每次写完一篇文章都要手动更新博文目录和相关链接信息，相信谁都会疯掉，所以hexo所做的就是将这些md文件都放在本地，每次写完文章后调用写好的命令来批量完成相关页面的生成，然后再将有改动的页面提交到github。 3.3 注意事项安装之前先来说几个注意事项： 很多命令既可以用Windows的cmd来完成，也可以使用git bash来完成，但是部分命令会有一些问题，为避免不必要的问题，建议全部使用git bash来执行； hexo不同版本差别比较大，网上很多文章的配置信息都是基于2.x的，所以注意不要被误导； hexo有2种_config.yml文件，一个是根目录下的全局的_config.yml，一个是各个theme下的； 3.4 安装1$ npm install -g hexo 3.5 初始化在电脑的某个地方新建一个名为hexo的文件夹（名字可以随便取），比如我的是F:\\Workspaces\\hexo，由于这个文件夹将来就作为你存放代码的地方，所以最好不要随便放。 12$ cd /f/Workspaces/hexo/$ hexo init hexo会自动下载一些文件到这个目录，包括node_modules，目录结构如下图： first-blog_3 12$ hexo g # 生成$ hexo s # 启动服务 执行以上命令之后，hexo就会在public文件夹生成相关html文件，这些文件将来都是要提交到github去的： first-blog_4 hexo s是开启本地预览服务，打开浏览器访问 http://localhost:4000 即可看到内容，很多人会碰到浏览器一直在转圈但是就是加载不出来的问题，一般情况下是因为端口占用的缘故，因为4000这个端口太常见了，解决端口冲突问题请参考这篇文章： http://blog.liuxianan.com/windows-port-bind.html 第一次初始化的时候hexo已经帮我们写了一篇名为 Hello World 的文章，默认的主题比较丑，打开时就是这个样子： first-blog_5 3.6 修改主题既然默认主题很丑，那我们别的不做，首先来替换一个好看点的主题。这是 官方主题。 个人比较喜欢的2个主题：hexo-theme-jekyll 和 hexo-theme-yilia。 首先下载这个主题： 12$ cd /f/Workspaces/hexo/$ git clone https://github.com/litten/hexo-theme-yilia.git themes/yilia 下载后的主题都在这里： first-blog_6 修改_config.yml中的theme: landscape改为theme: yilia，然后重新执行hexo g来重新生成。 如果出现一些莫名其妙的问题，可以先执行hexo clean来清理一下public的内容，然后再来重新生成和发布。 3.7 上传之前在上传代码到github之前，一定要记得先把你以前所有代码下载下来（虽然github有版本管理，但备份一下总是好的），因为从hexo提交代码时会把你以前的所有代码都删掉。 3.8 上传到github果你一切都配置好了，发布上传很容易，一句hexo d就搞定，当然关键还是你要把所有东西配置好。 首先，ssh key肯定要配置好。 其次，配置_config.yml中有关deploy的部分： 正确写法： 1234deploy: type: git repository: git@github.com:liuxianan/liuxianan.github.io.git branch: master 错误写法： 1234deploy: type: github repository: https://github.com/liuxianan/liuxianan.github.io.git branch: master 后面一种写法是hexo2.x的写法，现在已经不行了，无论是哪种写法，此时直接执行hexo d的话一般会报如下错误： 1Deployer not found: github 或者 Deployer not found: git 原因是还需要安装一个插件： 1npm install hexo-deployer-git --save 其它命令不确定，部署这个命令一定要用git bash，否则会提示Permission denied (publickey). 打开你的git bash，输入hexo d就会将本次有改动的代码全部提交，没有改动的不会： first-blog_7 3.9 保留CHANE、README.md等文件提交之后网页上一看，发现以前其它代码都没了，此时不要慌，一些非md文件可以把他们放到source文件夹下，这里的所有文件都会原样复制（除了md文件）到public目录的： first-blog_8 由于hexo默认会把所有md文件都转换成html，包括README.md，所有需要每次生成之后、上传之前，手动将README.md复制到public目录，并删除README.html。 3.10 常用hexo命令常见命令 1234567hexo new &quot;postName&quot; #新建文章hexo new page &quot;pageName&quot; #新建页面hexo generate #生成静态页面至public目录hexo server #开启预览访问端口（默认端口4000，&apos;ctrl + c&apos;关闭server）hexo deploy #部署到GitHubhexo help # 查看帮助hexo version #查看Hexo的版本 缩写： 1234hexo n == hexo newhexo g == hexo generatehexo s == hexo serverhexo d == hexo deploy 组合命令： 12hexo s -g #生成并本地预览hexo d -g #生成并上传 3.11 _config.yml这里面都是一些全局配置，每个参数的意思都比较简单明了，所以就不作详细介绍了。 需要特别注意的地方是，冒号后面必须有一个空格，否则可能会出问题。 3.12 创建文章定位到我们的hexo根目录，执行命令： 1hexo new &apos;my-first-blog&apos; hexo会帮我们在_posts下生成相关md文件： first-blog_9 我们只需要打开这个文件就可以开始写博客了，默认生成如下内容： first-blog_10 当然你也可以直接自己新建md文件，用这个命令的好处是帮我们自动生成了时间。 一般完整格式如下： 123456789---title: postName #文章页面上的显示名称，一般是中文date: 2013-12-02 15:30:16 #文章生成时间，一般不改，当然也可以任意修改categories: 默认分类 #分类tags: [tag1,tag2,tag3] #文章标签，可空，多标签请用格式，注意:后面有个空格description: 附加一段文章摘要，字数最好在140字以内，会出现在meta的description里面---以下是正文 那么hexo new page &#39;postName&#39;命令和hexo new &#39;postName&#39;有什么区别呢？ 1hexo new page &quot;my-second-blog&quot; 生成如下： first-blog_11 最终部署时生成：hexo\\public\\my-second-blog\\index.html，但是它不会作为文章出现在博文目录。 3.13 第三方文章编排的工具hexo是以markdown语法定义的文章，以md后缀名为结尾的文件，hexo将这个文件最终编辑成html页面。 本篇文章就是用markdown工具typora进行编辑的。 3.14 如何让博文列表不显示全部内容默认情况下，生成的博文目录会显示全部的文章内容，如何设置文章摘要的长度呢？ 答案是在合适的位置加上&lt;!--more--&gt;即可，例如： 123456789101112# 前言使用github pages服务搭建博客的好处有：1. 全是静态文件，访问速度快；2. 免费方便，不用花一分钱就可以搭建一个自由的个人博客，不需要服务器不需要后台；3. 可以随意绑定自己的域名，不仔细看的话根本看不出来你的网站是基于github的；&lt;!--more--&gt;4. 数据绝对安全，基于github的版本管理，想恢复到哪个历史版本都行；5. 博客内容可以轻松打包、转移、发布到其它平台；6. 等等； 最终效果： first-blog_12","categories":[],"tags":[{"name":"站长","slug":"站长","permalink":"http://www.xmidou.com/tags/站长/"},{"name":"爱好","slug":"爱好","permalink":"http://www.xmidou.com/tags/爱好/"}]}]}